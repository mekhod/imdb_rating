{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing IMDB Data in Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.datasets import imdb\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.optimizers import SGD\n",
    "from keras.optimizers import Adam\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading the data\n",
    "This dataset comes preloaded with Keras, so one simple command will get us training and testing data. There is a parameter for how many words we want to look at. We've set it at 1000, but feel free to experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000,)\n",
      "(25000,)\n"
     ]
    }
   ],
   "source": [
    "# Loading the data (it's preloaded in Keras)\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=1000)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Examining the data\n",
    "Notice that the data has been already pre-processed, where all the words have numbers, and the reviews come in as a vector with the words that the review contains. For example, if the word 'the' is the first one in our dictionary, and a review contains the word 'the', then there is a 1 in the corresponding vector.\n",
    "\n",
    "The output comes as a vector of 1's and 0's, where 1 is a positive sentiment for the review, and 0 is negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 14, 22, 16, 43, 530, 973, 2, 2, 65, 458, 2, 66, 2, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 2, 2, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2, 19, 14, 22, 4, 2, 2, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 2, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2, 2, 16, 480, 66, 2, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 2, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 2, 15, 256, 4, 2, 7, 2, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 2, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2, 56, 26, 141, 6, 194, 2, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 2, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 2, 88, 12, 16, 283, 5, 16, 2, 113, 103, 32, 15, 16, 2, 19, 178, 32]\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(x_train[0])\n",
    "print(y_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. One-hot encoding the output\n",
    "Here, we'll turn the input vectors into (0,1)-vectors. For example, if the pre-processed vector contains the number 14, then in the processed vector, the 14th entry will be 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  1.  1.  0.  1.  1.  1.  1.  1.  1.  0.  0.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  0.  1.  1.  0.  0.  1.  1.  0.  1.  0.  1.  0.  1.  1.  0.  1.\n",
      "  1.  0.  1.  1.  0.  0.  0.  1.  0.  0.  1.  0.  1.  0.  1.  1.  1.  0.\n",
      "  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  0.  0.  0.  1.\n",
      "  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.\n",
      "  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  1.  1.  0.  1.  1.\n",
      "  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.\n",
      "  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  1.  0.  0.\n",
      "  1.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  1.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "# One-hot encoding the output into vector mode, each of length 1000\n",
    "tokenizer = Tokenizer(num_words=1000)\n",
    "x_train_tok = tokenizer.sequences_to_matrix(x_train, mode='binary')\n",
    "x_test_tok = tokenizer.sequences_to_matrix(x_test, mode='binary')\n",
    "print(x_train_tok[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 1000)\n"
     ]
    }
   ],
   "source": [
    "print(x_train_tok.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we'll also one-hot encode the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 2)\n",
      "(25000, 2)\n"
     ]
    }
   ],
   "source": [
    "# One-hot encoding the output\n",
    "num_classes = 2\n",
    "y_train_tok = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test_tok = keras.utils.to_categorical(y_test, num_classes)\n",
    "print(y_train_tok.shape)\n",
    "print(y_test_tok.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train_tok = y_train_tok[:, 1]\n",
    "y_test_tok = y_test_tok[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000,)\n",
      "(25000,)\n"
     ]
    }
   ],
   "source": [
    "print(y_train_tok.shape)\n",
    "print(y_test_tok.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train_tok = np.reshape(y_train_tok, (y_train_tok.shape[0], 1))\n",
    "y_test_tok = np.reshape(y_test_tok, (y_test_tok.shape[0], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       ..., \n",
       "       [ 0.],\n",
       "       [ 1.],\n",
       "       [ 0.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_tok"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Building the  model architecture\n",
    "Build a model here using sequential. Feel free to experiment with different layers and sizes! Also, experiment adding dropout to reduce overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Here the optimizers are defined.\n",
    "adam = Adam(lr=0.00005)\n",
    "sgd = SGD(lr=0.005, decay=1e-6, momentum=0.9, nesterov=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def construct_model(optimizer=adam):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units = 1000, kernel_initializer = 'uniform', activation='relu', \n",
    "                    input_dim=1000))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(units = 500, kernel_initializer = 'uniform', activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(units = 1, kernel_initializer = 'uniform', activation='sigmoid'))\n",
    "    # to compile the model using a loss function and an optimizer.\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_61 (Dense)             (None, 1000)              1001000   \n",
      "_________________________________________________________________\n",
      "dropout_41 (Dropout)         (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_62 (Dense)             (None, 500)               500500    \n",
      "_________________________________________________________________\n",
      "dropout_42 (Dropout)         (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_63 (Dense)             (None, 1)                 501       \n",
      "=================================================================\n",
      "Total params: 1,502,001\n",
      "Trainable params: 1,502,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = construct_model(optimizer=sgd)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Training the model\n",
    "Run the model here. Experiment with different batch_size, and number of epochs!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00000: val_acc improved from -inf to 0.84340, saving model to ./weights.hdf5\n",
      "Epoch 00001: val_acc improved from 0.84340 to 0.85508, saving model to ./weights.hdf5\n",
      "Epoch 00002: val_acc improved from 0.85508 to 0.85808, saving model to ./weights.hdf5\n",
      "Epoch 00003: val_acc improved from 0.85808 to 0.85820, saving model to ./weights.hdf5\n",
      "Epoch 00004: val_acc did not improve\n",
      "Epoch 00005: val_acc did not improve\n",
      "Epoch 00006: val_acc improved from 0.85820 to 0.85888, saving model to ./weights.hdf5\n",
      "Epoch 00007: val_acc did not improve\n",
      "Epoch 00008: val_acc did not improve\n",
      "Epoch 00009: val_acc did not improve\n",
      "Epoch 00010: val_acc did not improve\n",
      "Epoch 00011: val_acc did not improve\n",
      "Epoch 00012: val_acc did not improve\n",
      "Epoch 00013: val_acc did not improve\n",
      "Epoch 00014: val_acc did not improve\n"
     ]
    }
   ],
   "source": [
    "checkpointer = ModelCheckpoint('./weights.hdf5', monitor='val_acc', verbose=1,\n",
    "                               save_best_only=True, mode='max')\n",
    "\n",
    "hist = model.fit(x_train_tok, y_train_tok,\n",
    "                 batch_size=32,\n",
    "                 epochs=15,\n",
    "                 validation_data=(x_test_tok, y_test_tok),\n",
    "                 callbacks=[checkpointer],\n",
    "                 verbose=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_history(hist, title=''):\n",
    "    ##\n",
    "    plt.plot(hist.history['acc'])\n",
    "    plt.plot(hist.history['val_acc'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.title(title)\n",
    "    plt.legend(['train', 'validation'], loc='upper left')\n",
    "    plt.show()\n",
    "    ##\n",
    "    plt.plot(hist.history['loss'])\n",
    "    plt.plot(hist.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.title(title)\n",
    "    plt.legend(['train', 'validation'], loc='upper left')\n",
    "    plt.yscale('log')\n",
    "    plt.show()\n",
    "    ##\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEKCAYAAAAB0GKPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nI6ovSv0iAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f58dc9be518>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZ8AAAEKCAYAAADNSVhkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f59b3794c88>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_history(hist=hist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Evaluating the model\n",
    "This will give you the accuracy of the model, as evaluated on the testing set. Can you get something over 85%?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate_model(model_builder=construct_model, optimizer=sgd, weights='weights.hdf5',\n",
    "                  x_val=x_test_tok, y_val=y_test_tok):\n",
    "    ##\n",
    "    model = model_builder(optimizer=optimizer)\n",
    "    model.load_weights(weights)\n",
    "    score = model.evaluate(x_val, y_val, verbose=0)\n",
    "    ##\n",
    "    return print(\"Accuracy: \", score[1])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.86092\n"
     ]
    }
   ],
   "source": [
    "evaluate_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Changing Optimizer\n",
    "Here we change the optimizer to adam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_2 = construct_model(optimizer=adam)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00000: val_acc improved from -inf to 0.85384, saving model to ./weights_2.hdf5\n",
      "Epoch 00001: val_acc improved from 0.85384 to 0.86208, saving model to ./weights_2.hdf5\n",
      "Epoch 00002: val_acc did not improve\n",
      "Epoch 00003: val_acc did not improve\n",
      "Epoch 00004: val_acc did not improve\n",
      "Epoch 00005: val_acc did not improve\n",
      "Epoch 00006: val_acc did not improve\n",
      "Epoch 00007: val_acc did not improve\n",
      "Epoch 00008: val_acc did not improve\n",
      "Epoch 00009: val_acc did not improve\n",
      "Epoch 00010: val_acc did not improve\n",
      "Epoch 00011: val_acc did not improve\n",
      "Epoch 00012: val_acc did not improve\n",
      "Epoch 00013: val_acc did not improve\n",
      "Epoch 00014: val_acc did not improve\n"
     ]
    }
   ],
   "source": [
    "checkpointer = ModelCheckpoint('./weights_2.hdf5', monitor='val_acc', verbose=1,\n",
    "                               save_best_only=True, mode='max')\n",
    "\n",
    "hist_2 = model_2.fit(x_train_tok, y_train_tok,\n",
    "                 batch_size=32,\n",
    "                 epochs=15,\n",
    "                 validation_data=(x_test_tok, y_test_tok),\n",
    "                 callbacks=[checkpointer],\n",
    "                 verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEKCAYAAAA4t9PUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJRJjjDEdYonEGGNMh/z/94IzMRJvge8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3294439f60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEKCAYAAAAFJbKyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f32944a0be0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_history(hist=hist_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.86208\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(model_builder=construct_model, optimizer=adam, weights='weights_2.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. k-Fold Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_total = np.concatenate((x_train_tok, x_test_tok), axis=0)\n",
    "y_total = np.concatenate((y_train_tok, y_test_tok), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# to wrap the keras model in KerasClassifier so it can be used by scikit-learn\n",
    "neural_net = KerasClassifier(build_fn=construct_model, \n",
    "                             epochs=2, \n",
    "                             batch_size=50, \n",
    "                             verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scores = cross_val_score(neural_net, x_total, y_total, cv=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.8624    ,  0.86839999,  0.8652    ,  0.8696    ,  0.86199999,\n",
       "        0.86119999,  0.85759999,  0.8752    ,  0.87719999,  0.86559999,\n",
       "        0.86919999,  0.8788    ,  0.87879999,  0.86839999,  0.86199999,\n",
       "        0.86159999,  0.86479999,  0.8588    ,  0.87279999,  0.86039999])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 9. Grid-Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "22380/22500 [============================>.] - ETA: 0s - loss: 0.4063 - acc: 0.8133Epoch 00000: loss improved from inf to 0.40583, saving model to ./weights_3.hdf5\n",
      "22500/22500 [==============================] - 11s - loss: 0.4058 - acc: 0.8135    \n",
      "Epoch 2/2\n",
      "22380/22500 [============================>.] - ETA: 0s - loss: 0.3145 - acc: 0.8669Epoch 00001: loss improved from 0.40583 to 0.31444, saving model to ./weights_3.hdf5\n",
      "22500/22500 [==============================] - 6s - loss: 0.3144 - acc: 0.8670     \n",
      "2220/2500 [=========================>....] - ETA: 0sEpoch 1/2\n",
      "22380/22500 [============================>.] - ETA: 0s - loss: 0.4045 - acc: 0.8167Epoch 00000: loss did not improve\n",
      "22500/22500 [==============================] - 10s - loss: 0.4041 - acc: 0.8169    \n",
      "Epoch 2/2\n",
      "22380/22500 [============================>.] - ETA: 0s - loss: 0.3130 - acc: 0.8691Epoch 00001: loss improved from 0.31444 to 0.31334, saving model to ./weights_3.hdf5\n",
      "22500/22500 [==============================] - 8s - loss: 0.3133 - acc: 0.8690     \n",
      "2460/2500 [============================>.] - ETA: 0sEpoch 1/2\n",
      "22380/22500 [============================>.] - ETA: 0s - loss: 0.4077 - acc: 0.8135Epoch 00000: loss did not improve\n",
      "22500/22500 [==============================] - 9s - loss: 0.4072 - acc: 0.8137     \n",
      "Epoch 2/2\n",
      "22380/22500 [============================>.] - ETA: 0s - loss: 0.3155 - acc: 0.8680Epoch 00001: loss did not improve\n",
      "22500/22500 [==============================] - 6s - loss: 0.3154 - acc: 0.8680     \n",
      "2100/2500 [========================>.....] - ETA: 0sEpoch 1/2\n",
      "22440/22500 [============================>.] - ETA: 0s - loss: 0.4083 - acc: 0.8158Epoch 00000: loss did not improve\n",
      "22500/22500 [==============================] - 9s - loss: 0.4081 - acc: 0.8160     \n",
      "Epoch 2/2\n",
      "22380/22500 [============================>.] - ETA: 0s - loss: 0.3165 - acc: 0.8653Epoch 00001: loss did not improve\n",
      "22500/22500 [==============================] - 6s - loss: 0.3161 - acc: 0.8656     \n",
      "2160/2500 [========================>.....] - ETA: 0sEpoch 1/2\n",
      "22380/22500 [============================>.] - ETA: 0s - loss: 0.4052 - acc: 0.8183Epoch 00000: loss did not improve\n",
      "22500/22500 [==============================] - 9s - loss: 0.4048 - acc: 0.8185     \n",
      "Epoch 2/2\n",
      "22380/22500 [============================>.] - ETA: 0s - loss: 0.3160 - acc: 0.8650Epoch 00001: loss did not improve\n",
      "22500/22500 [==============================] - 6s - loss: 0.3158 - acc: 0.8652     \n",
      "2500/2500 [==============================] - 2s     \n",
      "Epoch 1/2\n",
      "22440/22500 [============================>.] - ETA: 0s - loss: 0.4072 - acc: 0.8142Epoch 00000: loss did not improve\n",
      "22500/22500 [==============================] - 9s - loss: 0.4070 - acc: 0.8143     \n",
      "Epoch 2/2\n",
      "22380/22500 [============================>.] - ETA: 0s - loss: 0.3167 - acc: 0.8647Epoch 00001: loss did not improve\n",
      "22500/22500 [==============================] - 6s - loss: 0.3165 - acc: 0.8649     \n",
      "2460/2500 [============================>.] - ETA: 0sEpoch 1/2\n",
      "22380/22500 [============================>.] - ETA: 0s - loss: 0.4040 - acc: 0.8176Epoch 00000: loss did not improve\n",
      "22500/22500 [==============================] - 9s - loss: 0.4039 - acc: 0.8176     \n",
      "Epoch 2/2\n",
      "22380/22500 [============================>.] - ETA: 0s - loss: 0.3130 - acc: 0.8680Epoch 00001: loss improved from 0.31334 to 0.31259, saving model to ./weights_3.hdf5\n",
      "22500/22500 [==============================] - 7s - loss: 0.3126 - acc: 0.8683     \n",
      "2100/2500 [========================>.....] - ETA: 0sEpoch 1/2\n",
      "22440/22500 [============================>.] - ETA: 0s - loss: 0.4108 - acc: 0.8143Epoch 00000: loss did not improve\n",
      "22500/22500 [==============================] - 9s - loss: 0.4104 - acc: 0.8145     \n",
      "Epoch 2/2\n",
      "22380/22500 [============================>.] - ETA: 0s - loss: 0.3133 - acc: 0.8669Epoch 00001: loss did not improve\n",
      "22500/22500 [==============================] - 6s - loss: 0.3134 - acc: 0.8669     \n",
      "2500/2500 [==============================] - 2s     \n",
      "Epoch 1/2\n",
      "22380/22500 [============================>.] - ETA: 0s - loss: 0.4101 - acc: 0.8138Epoch 00000: loss did not improve\n",
      "22500/22500 [==============================] - 9s - loss: 0.4096 - acc: 0.8140     \n",
      "Epoch 2/2\n",
      "22380/22500 [============================>.] - ETA: 0s - loss: 0.3167 - acc: 0.8668Epoch 00001: loss did not improve\n",
      "22500/22500 [==============================] - 6s - loss: 0.3166 - acc: 0.8669     \n",
      "2500/2500 [==============================] - 2s     \n",
      "Epoch 1/2\n",
      "22380/22500 [============================>.] - ETA: 0s - loss: 0.4056 - acc: 0.8142Epoch 00000: loss did not improve\n",
      "22500/22500 [==============================] - 10s - loss: 0.4051 - acc: 0.8145    \n",
      "Epoch 2/2\n",
      "22380/22500 [============================>.] - ETA: 0s - loss: 0.3161 - acc: 0.8671Epoch 00001: loss did not improve\n",
      "22500/22500 [==============================] - 6s - loss: 0.3161 - acc: 0.8672     \n",
      "2460/2500 [============================>.] - ETA: 0sEpoch 1/3\n",
      "22380/22500 [============================>.] - ETA: 0s - loss: 0.4017 - acc: 0.8196Epoch 00000: loss did not improve\n",
      "22500/22500 [==============================] - 10s - loss: 0.4010 - acc: 0.8200    \n",
      "Epoch 2/3\n",
      "22380/22500 [============================>.] - ETA: 0s - loss: 0.3125 - acc: 0.8683Epoch 00001: loss improved from 0.31259 to 0.31228, saving model to ./weights_3.hdf5\n",
      "22500/22500 [==============================] - 8s - loss: 0.3123 - acc: 0.8685     \n",
      "Epoch 3/3\n",
      "22380/22500 [============================>.] - ETA: 0s - loss: 0.2872 - acc: 0.8816Epoch 00002: loss improved from 0.31228 to 0.28720, saving model to ./weights_3.hdf5\n",
      "22500/22500 [==============================] - 6s - loss: 0.2872 - acc: 0.8816     \n",
      "2460/2500 [============================>.] - ETA: 0sEpoch 1/3\n",
      "22380/22500 [============================>.] - ETA: 0s - loss: 0.4040 - acc: 0.8137Epoch 00000: loss did not improve\n",
      "22500/22500 [==============================] - 10s - loss: 0.4039 - acc: 0.8139    \n",
      "Epoch 2/3\n",
      "22380/22500 [============================>.] - ETA: 0s - loss: 0.3165 - acc: 0.8677Epoch 00001: loss did not improve\n",
      "22500/22500 [==============================] - 6s - loss: 0.3168 - acc: 0.8674     \n",
      "Epoch 3/3\n",
      "22380/22500 [============================>.] - ETA: 0s - loss: 0.2928 - acc: 0.8765Epoch 00002: loss did not improve\n",
      "22500/22500 [==============================] - 6s - loss: 0.2929 - acc: 0.8765     \n",
      "2500/2500 [==============================] - 3s     \n",
      "Epoch 1/3\n",
      "22380/22500 [============================>.] - ETA: 0s - loss: 0.4049 - acc: 0.8165Epoch 00000: loss did not improve\n",
      "22500/22500 [==============================] - 10s - loss: 0.4046 - acc: 0.8165    \n",
      "Epoch 2/3\n",
      "22380/22500 [============================>.] - ETA: 0s - loss: 0.3155 - acc: 0.8672Epoch 00001: loss did not improve\n",
      "22500/22500 [==============================] - 6s - loss: 0.3152 - acc: 0.8673     \n",
      "Epoch 3/3\n",
      "22380/22500 [============================>.] - ETA: 0s - loss: 0.2870 - acc: 0.8794Epoch 00002: loss improved from 0.28720 to 0.28685, saving model to ./weights_3.hdf5\n",
      "22500/22500 [==============================] - 8s - loss: 0.2869 - acc: 0.8794     \n",
      "2460/2500 [============================>.] - ETA: 0sEpoch 1/3\n",
      "22380/22500 [============================>.] - ETA: 0s - loss: 0.4070 - acc: 0.8182Epoch 00000: loss did not improve\n",
      "22500/22500 [==============================] - 10s - loss: 0.4064 - acc: 0.8185    \n",
      "Epoch 2/3\n",
      "22380/22500 [============================>.] - ETA: 0s - loss: 0.3177 - acc: 0.8662Epoch 00001: loss did not improve\n",
      "22500/22500 [==============================] - 6s - loss: 0.3179 - acc: 0.8663     \n",
      "Epoch 3/3\n",
      "22380/22500 [============================>.] - ETA: 0s - loss: 0.2909 - acc: 0.8797Epoch 00002: loss did not improve\n",
      "22500/22500 [==============================] - 6s - loss: 0.2911 - acc: 0.8796     \n",
      "2460/2500 [============================>.] - ETA: 0sEpoch 1/3\n",
      "22380/22500 [============================>.] - ETA: 0s - loss: 0.4053 - acc: 0.8164Epoch 00000: loss did not improve\n",
      "22500/22500 [==============================] - 10s - loss: 0.4048 - acc: 0.8167    \n",
      "Epoch 2/3\n",
      "22380/22500 [============================>.] - ETA: 0s - loss: 0.3168 - acc: 0.8679Epoch 00001: loss did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22500/22500 [==============================] - 6s - loss: 0.3171 - acc: 0.8676     \n",
      "Epoch 3/3\n",
      "22380/22500 [============================>.] - ETA: 0s - loss: 0.2877 - acc: 0.8794Epoch 00002: loss did not improve\n",
      "22500/22500 [==============================] - 6s - loss: 0.2876 - acc: 0.8795     \n",
      "2500/2500 [==============================] - 3s     \n",
      "Epoch 1/3\n",
      "22380/22500 [============================>.] - ETA: 0s - loss: 0.4075 - acc: 0.8158Epoch 00000: loss did not improve\n",
      "22500/22500 [==============================] - 10s - loss: 0.4076 - acc: 0.8156    \n",
      "Epoch 2/3\n",
      "22380/22500 [============================>.] - ETA: 0s - loss: 0.3137 - acc: 0.8699Epoch 00001: loss did not improve\n",
      "22500/22500 [==============================] - 6s - loss: 0.3133 - acc: 0.8701     \n",
      "Epoch 3/3\n",
      "22380/22500 [============================>.] - ETA: 0s - loss: 0.2886 - acc: 0.8798Epoch 00002: loss did not improve\n",
      "22500/22500 [==============================] - 6s - loss: 0.2890 - acc: 0.8797     \n",
      "2400/2500 [===========================>..] - ETA: 0sEpoch 1/3\n",
      "22380/22500 [============================>.] - ETA: 0s - loss: 0.4045 - acc: 0.8187Epoch 00000: loss did not improve\n",
      "22500/22500 [==============================] - 10s - loss: 0.4045 - acc: 0.8188    \n",
      "Epoch 2/3\n",
      "22380/22500 [============================>.] - ETA: 0s - loss: 0.3117 - acc: 0.8688Epoch 00001: loss did not improve\n",
      "22500/22500 [==============================] - 6s - loss: 0.3116 - acc: 0.8688     \n",
      "Epoch 3/3\n",
      "22380/22500 [============================>.] - ETA: 0s - loss: 0.2867 - acc: 0.8808Epoch 00002: loss improved from 0.28685 to 0.28655, saving model to ./weights_3.hdf5\n",
      "22500/22500 [==============================] - 8s - loss: 0.2866 - acc: 0.8807     \n",
      "2460/2500 [============================>.] - ETA: 0sEpoch 1/3\n",
      "22380/22500 [============================>.] - ETA: 0s - loss: 0.4054 - acc: 0.8141Epoch 00000: loss did not improve\n",
      "22500/22500 [==============================] - 10s - loss: 0.4052 - acc: 0.8144    \n",
      "Epoch 2/3\n",
      "22380/22500 [============================>.] - ETA: 0s - loss: 0.3162 - acc: 0.8665Epoch 00001: loss did not improve\n",
      "22500/22500 [==============================] - 6s - loss: 0.3171 - acc: 0.8664     \n",
      "Epoch 3/3\n",
      "22380/22500 [============================>.] - ETA: 0s - loss: 0.2894 - acc: 0.8811Epoch 00002: loss did not improve\n",
      "22500/22500 [==============================] - 6s - loss: 0.2892 - acc: 0.8813     \n",
      "2400/2500 [===========================>..] - ETA: 0sEpoch 1/3\n",
      "22380/22500 [============================>.] - ETA: 0s - loss: 0.4046 - acc: 0.8162Epoch 00000: loss did not improve\n",
      "22500/22500 [==============================] - 10s - loss: 0.4044 - acc: 0.8164    \n",
      "Epoch 2/3\n",
      "22380/22500 [============================>.] - ETA: 0s - loss: 0.3170 - acc: 0.8665Epoch 00001: loss did not improve\n",
      "22500/22500 [==============================] - 6s - loss: 0.3166 - acc: 0.8667     \n",
      "Epoch 3/3\n",
      "22380/22500 [============================>.] - ETA: 0s - loss: 0.2891 - acc: 0.8800Epoch 00002: loss did not improve\n",
      "22500/22500 [==============================] - 6s - loss: 0.2888 - acc: 0.8801     \n",
      "2500/2500 [==============================] - 3s     \n",
      "Epoch 1/3\n",
      "22380/22500 [============================>.] - ETA: 0s - loss: 0.4042 - acc: 0.8163Epoch 00000: loss did not improve\n",
      "22500/22500 [==============================] - 10s - loss: 0.4039 - acc: 0.8164    \n",
      "Epoch 2/3\n",
      "22380/22500 [============================>.] - ETA: 0s - loss: 0.3121 - acc: 0.8687Epoch 00001: loss did not improve\n",
      "22500/22500 [==============================] - 6s - loss: 0.3116 - acc: 0.8690     \n",
      "Epoch 3/3\n",
      "22380/22500 [============================>.] - ETA: 0s - loss: 0.2867 - acc: 0.8794Epoch 00002: loss did not improve\n",
      "22500/22500 [==============================] - 6s - loss: 0.2868 - acc: 0.8794     \n",
      "2500/2500 [==============================] - 3s     \n",
      "Epoch 1/4\n",
      "22380/22500 [============================>.] - ETA: 0s - loss: 0.4110 - acc: 0.8091Epoch 00000: loss did not improve\n",
      "22500/22500 [==============================] - 10s - loss: 0.4106 - acc: 0.8093    \n",
      "Epoch 2/4\n",
      "22380/22500 [============================>.] - ETA: 0s - loss: 0.3145 - acc: 0.8664Epoch 00001: loss did not improve\n",
      "22500/22500 [==============================] - 6s - loss: 0.3141 - acc: 0.8665     \n",
      "Epoch 3/4\n",
      "22380/22500 [============================>.] - ETA: 0s - loss: 0.2863 - acc: 0.8811Epoch 00002: loss improved from 0.28655 to 0.28623, saving model to ./weights_3.hdf5\n",
      "22500/22500 [==============================] - 8s - loss: 0.2862 - acc: 0.8809     \n",
      "Epoch 4/4\n",
      "22380/22500 [============================>.] - ETA: 0s - loss: 0.2604 - acc: 0.8924Epoch 00003: loss improved from 0.28623 to 0.26056, saving model to ./weights_3.hdf5\n",
      "22500/22500 [==============================] - 6s - loss: 0.2606 - acc: 0.8925     \n",
      "2460/2500 [============================>.] - ETA: 0sEpoch 1/4\n",
      "22380/22500 [============================>.] - ETA: 0s - loss: 0.4049 - acc: 0.8169Epoch 00000: loss did not improve\n",
      "22500/22500 [==============================] - 10s - loss: 0.4049 - acc: 0.8168    \n",
      "Epoch 2/4\n",
      "22380/22500 [============================>.] - ETA: 0s - loss: 0.3118 - acc: 0.8712Epoch 00001: loss did not improve\n",
      "22500/22500 [==============================] - 6s - loss: 0.3114 - acc: 0.8713     \n",
      "Epoch 3/4\n",
      "22380/22500 [============================>.] - ETA: 0s - loss: 0.2891 - acc: 0.8799Epoch 00002: loss did not improve\n",
      "22500/22500 [==============================] - 6s - loss: 0.2891 - acc: 0.8797     \n",
      "Epoch 4/4\n",
      "22380/22500 [============================>.] - ETA: 0s - loss: 0.2612 - acc: 0.8910Epoch 00003: loss did not improve\n",
      "22500/22500 [==============================] - 6s - loss: 0.2612 - acc: 0.8910     \n",
      "2460/2500 [============================>.] - ETA: 0sEpoch 1/4\n",
      "22380/22500 [============================>.] - ETA: 0s - loss: 0.4050 - acc: 0.8155Epoch 00000: loss did not improve\n",
      "22500/22500 [==============================] - 14s - loss: 0.4048 - acc: 0.8157    \n",
      "Epoch 2/4\n",
      "22380/22500 [============================>.] - ETA: 0s - loss: 0.3154 - acc: 0.8656Epoch 00001: loss did not improve\n",
      "22500/22500 [==============================] - 6s - loss: 0.3154 - acc: 0.8657     \n",
      "Epoch 3/4\n",
      "22380/22500 [============================>.] - ETA: 0s - loss: 0.2867 - acc: 0.8820Epoch 00002: loss did not improve\n",
      "22500/22500 [==============================] - 6s - loss: 0.2868 - acc: 0.8820     \n",
      "Epoch 4/4\n",
      "22380/22500 [============================>.] - ETA: 0s - loss: 0.2609 - acc: 0.8929Epoch 00003: loss did not improve\n",
      "22500/22500 [==============================] - 6s - loss: 0.2607 - acc: 0.8930     \n",
      "2400/2500 [===========================>..] - ETA: 0sEpoch 1/4\n",
      "22380/22500 [============================>.] - ETA: 0s - loss: 0.4101 - acc: 0.8095Epoch 00000: loss did not improve\n",
      "22500/22500 [==============================] - 10s - loss: 0.4099 - acc: 0.8097    \n",
      "Epoch 2/4\n",
      "22380/22500 [============================>.] - ETA: 0s - loss: 0.3170 - acc: 0.8665Epoch 00001: loss did not improve\n",
      "22500/22500 [==============================] - 6s - loss: 0.3168 - acc: 0.8665     \n",
      "Epoch 3/4\n",
      "22380/22500 [============================>.] - ETA: 0s - loss: 0.2888 - acc: 0.8808Epoch 00002: loss did not improve\n",
      "22500/22500 [==============================] - 6s - loss: 0.2884 - acc: 0.8810     \n",
      "Epoch 4/4\n",
      "22380/22500 [============================>.] - ETA: 0s - loss: 0.2624 - acc: 0.8927Epoch 00003: loss did not improve\n",
      "22500/22500 [==============================] - 6s - loss: 0.2623 - acc: 0.8927     \n",
      "2500/2500 [==============================] - 3s     \n",
      "Epoch 1/4\n",
      "22380/22500 [============================>.] - ETA: 0s - loss: 0.4053 - acc: 0.8157Epoch 00000: loss did not improve\n",
      "22500/22500 [==============================] - 10s - loss: 0.4047 - acc: 0.8159    \n",
      "Epoch 2/4\n",
      "22380/22500 [============================>.] - ETA: 0s - loss: 0.3130 - acc: 0.8680Epoch 00001: loss did not improve\n",
      "22500/22500 [==============================] - 6s - loss: 0.3133 - acc: 0.8679     \n",
      "Epoch 3/4\n",
      "22380/22500 [============================>.] - ETA: 0s - loss: 0.2864 - acc: 0.8795Epoch 00002: loss did not improve\n",
      "22500/22500 [==============================] - 6s - loss: 0.2864 - acc: 0.8796     \n",
      "Epoch 4/4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22380/22500 [============================>.] - ETA: 0s - loss: 0.2604 - acc: 0.8927Epoch 00003: loss improved from 0.26056 to 0.26017, saving model to ./weights_3.hdf5\n",
      "22500/22500 [==============================] - 8s - loss: 0.2602 - acc: 0.8930     \n",
      "2460/2500 [============================>.] - ETA: 0sEpoch 1/4\n",
      "22380/22500 [============================>.] - ETA: 0s - loss: 0.4074 - acc: 0.8179Epoch 00000: loss did not improve\n",
      "22500/22500 [==============================] - 10s - loss: 0.4071 - acc: 0.8180    \n",
      "Epoch 2/4\n",
      "22380/22500 [============================>.] - ETA: 0s - loss: 0.3139 - acc: 0.8691Epoch 00001: loss did not improve\n",
      "22500/22500 [==============================] - 6s - loss: 0.3138 - acc: 0.8691     \n",
      "Epoch 3/4\n",
      "22380/22500 [============================>.] - ETA: 0s - loss: 0.2888 - acc: 0.8802Epoch 00002: loss did not improve\n",
      "22500/22500 [==============================] - 6s - loss: 0.2884 - acc: 0.8802     \n",
      "Epoch 4/4\n",
      "22380/22500 [============================>.] - ETA: 0s - loss: 0.2641 - acc: 0.8932Epoch 00003: loss did not improve\n",
      "22500/22500 [==============================] - 6s - loss: 0.2638 - acc: 0.8932     \n",
      "2400/2500 [===========================>..] - ETA: 0sEpoch 1/4\n",
      "22380/22500 [============================>.] - ETA: 0s - loss: 0.4072 - acc: 0.8142Epoch 00000: loss did not improve\n",
      "22500/22500 [==============================] - 10s - loss: 0.4068 - acc: 0.8145    \n",
      "Epoch 2/4\n",
      "22380/22500 [============================>.] - ETA: 0s - loss: 0.3142 - acc: 0.8682Epoch 00001: loss did not improve\n",
      "22500/22500 [==============================] - 6s - loss: 0.3144 - acc: 0.8681     \n",
      "Epoch 3/4\n",
      "22380/22500 [============================>.] - ETA: 0s - loss: 0.2864 - acc: 0.8780Epoch 00002: loss did not improve\n",
      "22500/22500 [==============================] - 6s - loss: 0.2866 - acc: 0.8777     \n",
      "Epoch 4/4\n",
      "22380/22500 [============================>.] - ETA: 0s - loss: 0.2606 - acc: 0.8941Epoch 00003: loss did not improve\n",
      "22500/22500 [==============================] - 6s - loss: 0.2605 - acc: 0.8942     \n",
      "2460/2500 [============================>.] - ETA: 0sEpoch 1/4\n",
      "22380/22500 [============================>.] - ETA: 0s - loss: 0.4087 - acc: 0.8139Epoch 00000: loss did not improve\n",
      "22500/22500 [==============================] - 10s - loss: 0.4081 - acc: 0.8141    \n",
      "Epoch 2/4\n",
      "22380/22500 [============================>.] - ETA: 0s - loss: 0.3119 - acc: 0.8697Epoch 00001: loss did not improve\n",
      "22500/22500 [==============================] - 6s - loss: 0.3118 - acc: 0.8697     \n",
      "Epoch 3/4\n",
      "22380/22500 [============================>.] - ETA: 0s - loss: 0.2867 - acc: 0.8810Epoch 00002: loss did not improve\n",
      "22500/22500 [==============================] - 6s - loss: 0.2872 - acc: 0.8807     \n",
      "Epoch 4/4\n",
      "22380/22500 [============================>.] - ETA: 0s - loss: 0.2593 - acc: 0.8954Epoch 00003: loss improved from 0.26017 to 0.25945, saving model to ./weights_3.hdf5\n",
      "22500/22500 [==============================] - 8s - loss: 0.2595 - acc: 0.8953     \n",
      "2400/2500 [===========================>..] - ETA: 0sEpoch 1/4\n",
      "22380/22500 [============================>.] - ETA: 0s - loss: 0.4049 - acc: 0.8168Epoch 00000: loss did not improve\n",
      "22500/22500 [==============================] - 10s - loss: 0.4049 - acc: 0.8168    \n",
      "Epoch 2/4\n",
      "22380/22500 [============================>.] - ETA: 0s - loss: 0.3153 - acc: 0.8663Epoch 00001: loss did not improve\n",
      "22500/22500 [==============================] - 6s - loss: 0.3149 - acc: 0.8665     \n",
      "Epoch 3/4\n",
      "22380/22500 [============================>.] - ETA: 0s - loss: 0.2893 - acc: 0.8798Epoch 00002: loss did not improve\n",
      "22500/22500 [==============================] - 6s - loss: 0.2900 - acc: 0.8795     \n",
      "Epoch 4/4\n",
      "22380/22500 [============================>.] - ETA: 0s - loss: 0.2631 - acc: 0.8927Epoch 00003: loss did not improve\n",
      "22500/22500 [==============================] - 6s - loss: 0.2631 - acc: 0.8928     \n",
      "2400/2500 [===========================>..] - ETA: 0sEpoch 1/4\n",
      "22380/22500 [============================>.] - ETA: 0s - loss: 0.4024 - acc: 0.8184Epoch 00000: loss did not improve\n",
      "22500/22500 [==============================] - 10s - loss: 0.4026 - acc: 0.8184    \n",
      "Epoch 2/4\n",
      "22380/22500 [============================>.] - ETA: 0s - loss: 0.3148 - acc: 0.8674Epoch 00001: loss did not improve\n",
      "22500/22500 [==============================] - 6s - loss: 0.3144 - acc: 0.8676     \n",
      "Epoch 3/4\n",
      "22380/22500 [============================>.] - ETA: 0s - loss: 0.2863 - acc: 0.8802Epoch 00002: loss did not improve\n",
      "22500/22500 [==============================] - 7s - loss: 0.2863 - acc: 0.8803     \n",
      "Epoch 4/4\n",
      "22380/22500 [============================>.] - ETA: 0s - loss: 0.2588 - acc: 0.8953Epoch 00003: loss improved from 0.25945 to 0.25876, saving model to ./weights_3.hdf5\n",
      "22500/22500 [==============================] - 8s - loss: 0.2588 - acc: 0.8952     \n",
      "2280/2500 [==========================>...] - ETA: 0sEpoch 1/2\n",
      "22350/22500 [============================>.] - ETA: 0s - loss: 0.4067 - acc: 0.8182Epoch 00000: loss did not improve\n",
      "22500/22500 [==============================] - 9s - loss: 0.4063 - acc: 0.8184     \n",
      "Epoch 2/2\n",
      "22350/22500 [============================>.] - ETA: 0s - loss: 0.3154 - acc: 0.8671Epoch 00001: loss did not improve\n",
      "22500/22500 [==============================] - 5s - loss: 0.3154 - acc: 0.8670     \n",
      "2400/2500 [===========================>..] - ETA: 0sEpoch 1/2\n",
      "22350/22500 [============================>.] - ETA: 0s - loss: 0.4082 - acc: 0.8161Epoch 00000: loss did not improve\n",
      "22500/22500 [==============================] - 9s - loss: 0.4076 - acc: 0.8167     \n",
      "Epoch 2/2\n",
      "22350/22500 [============================>.] - ETA: 0s - loss: 0.3173 - acc: 0.8661Epoch 00001: loss did not improve\n",
      "22500/22500 [==============================] - 5s - loss: 0.3170 - acc: 0.8663     \n",
      "2250/2500 [==========================>...] - ETA: 0sEpoch 1/2\n",
      "22350/22500 [============================>.] - ETA: 0s - loss: 0.4116 - acc: 0.8168Epoch 00000: loss did not improve\n",
      "22500/22500 [==============================] - 9s - loss: 0.4110 - acc: 0.8171     \n",
      "Epoch 2/2\n",
      "22350/22500 [============================>.] - ETA: 0s - loss: 0.3197 - acc: 0.8654Epoch 00001: loss did not improve\n",
      "22500/22500 [==============================] - 5s - loss: 0.3195 - acc: 0.8656     \n",
      "2175/2500 [=========================>....] - ETA: 0sEpoch 1/2\n",
      "22350/22500 [============================>.] - ETA: 0s - loss: 0.4126 - acc: 0.8126Epoch 00000: loss did not improve\n",
      "22500/22500 [==============================] - 9s - loss: 0.4123 - acc: 0.8127     \n",
      "Epoch 2/2\n",
      "22350/22500 [============================>.] - ETA: 0s - loss: 0.3161 - acc: 0.8670Epoch 00001: loss did not improve\n",
      "22500/22500 [==============================] - 5s - loss: 0.3158 - acc: 0.8672     \n",
      "2100/2500 [========================>.....] - ETA: 0sEpoch 1/2\n",
      "22350/22500 [============================>.] - ETA: 0s - loss: 0.4109 - acc: 0.8152Epoch 00000: loss did not improve\n",
      "22500/22500 [==============================] - 9s - loss: 0.4106 - acc: 0.8152     \n",
      "Epoch 2/2\n",
      "22350/22500 [============================>.] - ETA: 0s - loss: 0.3144 - acc: 0.8677Epoch 00001: loss did not improve\n",
      "22500/22500 [==============================] - 5s - loss: 0.3145 - acc: 0.8676     \n",
      "2175/2500 [=========================>....] - ETA: 0sEpoch 1/2\n",
      "22350/22500 [============================>.] - ETA: 0s - loss: 0.4102 - acc: 0.8147Epoch 00000: loss did not improve\n",
      "22500/22500 [==============================] - 9s - loss: 0.4098 - acc: 0.8151     \n",
      "Epoch 2/2\n",
      "22350/22500 [============================>.] - ETA: 0s - loss: 0.3154 - acc: 0.8675Epoch 00001: loss did not improve\n",
      "22500/22500 [==============================] - 5s - loss: 0.3153 - acc: 0.8675     \n",
      "2250/2500 [==========================>...] - ETA: 0sEpoch 1/2\n",
      "22350/22500 [============================>.] - ETA: 0s - loss: 0.4069 - acc: 0.8156Epoch 00000: loss did not improve\n",
      "22500/22500 [==============================] - 9s - loss: 0.4061 - acc: 0.8161     \n",
      "Epoch 2/2\n",
      "22350/22500 [============================>.] - ETA: 0s - loss: 0.3160 - acc: 0.8670Epoch 00001: loss did not improve\n",
      "22500/22500 [==============================] - 5s - loss: 0.3161 - acc: 0.8669     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2325/2500 [==========================>...] - ETA: 0sEpoch 1/2\n",
      "22350/22500 [============================>.] - ETA: 0s - loss: 0.4110 - acc: 0.8115Epoch 00000: loss did not improve\n",
      "22500/22500 [==============================] - 9s - loss: 0.4108 - acc: 0.8118     \n",
      "Epoch 2/2\n",
      "22350/22500 [============================>.] - ETA: 0s - loss: 0.3162 - acc: 0.8667Epoch 00001: loss did not improve\n",
      "22500/22500 [==============================] - 5s - loss: 0.3168 - acc: 0.8664     \n",
      "2250/2500 [==========================>...] - ETA: 0sEpoch 1/2\n",
      "22350/22500 [============================>.] - ETA: 0s - loss: 0.4107 - acc: 0.8143Epoch 00000: loss did not improve\n",
      "22500/22500 [==============================] - 9s - loss: 0.4097 - acc: 0.8146     \n",
      "Epoch 2/2\n",
      "22350/22500 [============================>.] - ETA: 0s - loss: 0.3163 - acc: 0.8685Epoch 00001: loss did not improve\n",
      "22500/22500 [==============================] - 5s - loss: 0.3164 - acc: 0.8684     \n",
      "2250/2500 [==========================>...] - ETA: 0sEpoch 1/2\n",
      "22350/22500 [============================>.] - ETA: 0s - loss: 0.4089 - acc: 0.8111Epoch 00000: loss did not improve\n",
      "22500/22500 [==============================] - 9s - loss: 0.4079 - acc: 0.8117     \n",
      "Epoch 2/2\n",
      "22350/22500 [============================>.] - ETA: 0s - loss: 0.3156 - acc: 0.8657Epoch 00001: loss did not improve\n",
      "22500/22500 [==============================] - 5s - loss: 0.3155 - acc: 0.8656     \n",
      "2175/2500 [=========================>....] - ETA: 0sEpoch 1/3\n",
      "22350/22500 [============================>.] - ETA: 0s - loss: 0.4075 - acc: 0.8140Epoch 00000: loss did not improve\n",
      "22500/22500 [==============================] - 9s - loss: 0.4066 - acc: 0.8144     \n",
      "Epoch 2/3\n",
      "22350/22500 [============================>.] - ETA: 0s - loss: 0.3157 - acc: 0.8687Epoch 00001: loss did not improve\n",
      "22500/22500 [==============================] - 5s - loss: 0.3154 - acc: 0.8687     \n",
      "Epoch 3/3\n",
      "22350/22500 [============================>.] - ETA: 0s - loss: 0.2873 - acc: 0.8817Epoch 00002: loss did not improve\n",
      "22500/22500 [==============================] - 5s - loss: 0.2874 - acc: 0.8816     \n",
      "2250/2500 [==========================>...] - ETA: 0sEpoch 1/3\n",
      "22350/22500 [============================>.] - ETA: 0s - loss: 0.4096 - acc: 0.8138Epoch 00000: loss did not improve\n",
      "22500/22500 [==============================] - 9s - loss: 0.4088 - acc: 0.8141     \n",
      "Epoch 2/3\n",
      "22350/22500 [============================>.] - ETA: 0s - loss: 0.3151 - acc: 0.8682Epoch 00001: loss did not improve\n",
      "22500/22500 [==============================] - 5s - loss: 0.3150 - acc: 0.8681     \n",
      "Epoch 3/3\n",
      "22350/22500 [============================>.] - ETA: 0s - loss: 0.2878 - acc: 0.8804Epoch 00002: loss did not improve\n",
      "22500/22500 [==============================] - 5s - loss: 0.2876 - acc: 0.8804     \n",
      "2250/2500 [==========================>...] - ETA: 0sEpoch 1/3\n",
      "22350/22500 [============================>.] - ETA: 0s - loss: 0.4113 - acc: 0.8135Epoch 00000: loss did not improve\n",
      "22500/22500 [==============================] - 9s - loss: 0.4106 - acc: 0.8140     \n",
      "Epoch 2/3\n",
      "22350/22500 [============================>.] - ETA: 0s - loss: 0.3174 - acc: 0.8643Epoch 00001: loss did not improve\n",
      "22500/22500 [==============================] - 5s - loss: 0.3172 - acc: 0.8644     \n",
      "Epoch 3/3\n",
      "22350/22500 [============================>.] - ETA: 0s - loss: 0.2891 - acc: 0.8810Epoch 00002: loss did not improve\n",
      "22500/22500 [==============================] - 5s - loss: 0.2893 - acc: 0.8809     \n",
      "2250/2500 [==========================>...] - ETA: 0sEpoch 1/3\n",
      "22350/22500 [============================>.] - ETA: 0s - loss: 0.4135 - acc: 0.8091Epoch 00000: loss did not improve\n",
      "22500/22500 [==============================] - 9s - loss: 0.4136 - acc: 0.8088     \n",
      "Epoch 2/3\n",
      "22350/22500 [============================>.] - ETA: 0s - loss: 0.3179 - acc: 0.8672Epoch 00001: loss did not improve\n",
      "22500/22500 [==============================] - 5s - loss: 0.3180 - acc: 0.8671     \n",
      "Epoch 3/3\n",
      "22350/22500 [============================>.] - ETA: 0s - loss: 0.2896 - acc: 0.8804Epoch 00002: loss did not improve\n",
      "22500/22500 [==============================] - 5s - loss: 0.2899 - acc: 0.8802     \n",
      "2325/2500 [==========================>...] - ETA: 0sEpoch 1/3\n",
      "22350/22500 [============================>.] - ETA: 0s - loss: 0.4120 - acc: 0.8093Epoch 00000: loss did not improve\n",
      "22500/22500 [==============================] - 9s - loss: 0.4115 - acc: 0.8096     \n",
      "Epoch 2/3\n",
      "22350/22500 [============================>.] - ETA: 0s - loss: 0.3141 - acc: 0.8685Epoch 00001: loss did not improve\n",
      "22500/22500 [==============================] - 5s - loss: 0.3140 - acc: 0.8684     \n",
      "Epoch 3/3\n",
      "22350/22500 [============================>.] - ETA: 0s - loss: 0.2867 - acc: 0.8825Epoch 00002: loss did not improve\n",
      "22500/22500 [==============================] - 5s - loss: 0.2863 - acc: 0.8828     \n",
      "2175/2500 [=========================>....] - ETA: 0sEpoch 1/3\n",
      "22350/22500 [============================>.] - ETA: 0s - loss: 0.4107 - acc: 0.8114Epoch 00000: loss did not improve\n",
      "22500/22500 [==============================] - 9s - loss: 0.4103 - acc: 0.8117     \n",
      "Epoch 2/3\n",
      "22350/22500 [============================>.] - ETA: 0s - loss: 0.3160 - acc: 0.8677Epoch 00001: loss did not improve\n",
      "22500/22500 [==============================] - 5s - loss: 0.3163 - acc: 0.8679     \n",
      "Epoch 3/3\n",
      "22350/22500 [============================>.] - ETA: 0s - loss: 0.2907 - acc: 0.8770Epoch 00002: loss did not improve\n",
      "22500/22500 [==============================] - 5s - loss: 0.2903 - acc: 0.8772     \n",
      "2175/2500 [=========================>....] - ETA: 0sEpoch 1/3\n",
      "22350/22500 [============================>.] - ETA: 0s - loss: 0.4063 - acc: 0.8122Epoch 00000: loss did not improve\n",
      "22500/22500 [==============================] - 9s - loss: 0.4059 - acc: 0.8121     \n",
      "Epoch 2/3\n",
      "22350/22500 [============================>.] - ETA: 0s - loss: 0.3135 - acc: 0.8677Epoch 00001: loss did not improve\n",
      "22500/22500 [==============================] - 5s - loss: 0.3133 - acc: 0.8678     \n",
      "Epoch 3/3\n",
      "22350/22500 [============================>.] - ETA: 0s - loss: 0.2845 - acc: 0.8809Epoch 00002: loss did not improve\n",
      "22500/22500 [==============================] - 5s - loss: 0.2849 - acc: 0.8807     \n",
      "2100/2500 [========================>.....] - ETA: 0sEpoch 1/3\n",
      "22350/22500 [============================>.] - ETA: 0s - loss: 0.4105 - acc: 0.8124Epoch 00000: loss did not improve\n",
      "22500/22500 [==============================] - 9s - loss: 0.4095 - acc: 0.8130     \n",
      "Epoch 2/3\n",
      "22350/22500 [============================>.] - ETA: 0s - loss: 0.3177 - acc: 0.8662Epoch 00001: loss did not improve\n",
      "22500/22500 [==============================] - 5s - loss: 0.3180 - acc: 0.8660     \n",
      "Epoch 3/3\n",
      "22350/22500 [============================>.] - ETA: 0s - loss: 0.2914 - acc: 0.8784Epoch 00002: loss did not improve\n",
      "22500/22500 [==============================] - 5s - loss: 0.2912 - acc: 0.8784     \n",
      "2100/2500 [========================>.....] - ETA: 0sEpoch 1/3\n",
      "22350/22500 [============================>.] - ETA: 0s - loss: 0.4119 - acc: 0.8153Epoch 00000: loss did not improve\n",
      "22500/22500 [==============================] - 9s - loss: 0.4114 - acc: 0.8155     \n",
      "Epoch 2/3\n",
      "22350/22500 [============================>.] - ETA: 0s - loss: 0.3192 - acc: 0.8649Epoch 00001: loss did not improve\n",
      "22500/22500 [==============================] - 5s - loss: 0.3194 - acc: 0.8647     \n",
      "Epoch 3/3\n",
      "22350/22500 [============================>.] - ETA: 0s - loss: 0.2904 - acc: 0.8791Epoch 00002: loss did not improve\n",
      "22500/22500 [==============================] - 5s - loss: 0.2905 - acc: 0.8792     \n",
      "2175/2500 [=========================>....] - ETA: 0sEpoch 1/3\n",
      "22350/22500 [============================>.] - ETA: 0s - loss: 0.4111 - acc: 0.8107Epoch 00000: loss did not improve\n",
      "22500/22500 [==============================] - 9s - loss: 0.4108 - acc: 0.8108     \n",
      "Epoch 2/3\n",
      "22350/22500 [============================>.] - ETA: 0s - loss: 0.3171 - acc: 0.8656Epoch 00001: loss did not improve\n",
      "22500/22500 [==============================] - 5s - loss: 0.3172 - acc: 0.8656     \n",
      "Epoch 3/3\n",
      "22350/22500 [============================>.] - ETA: 0s - loss: 0.2884 - acc: 0.8806Epoch 00002: loss did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22500/22500 [==============================] - 5s - loss: 0.2881 - acc: 0.8808     \n",
      "2250/2500 [==========================>...] - ETA: 0sEpoch 1/4\n",
      "22350/22500 [============================>.] - ETA: 0s - loss: 0.4058 - acc: 0.8157Epoch 00000: loss did not improve\n",
      "22500/22500 [==============================] - 9s - loss: 0.4058 - acc: 0.8156     \n",
      "Epoch 2/4\n",
      "22350/22500 [============================>.] - ETA: 0s - loss: 0.3163 - acc: 0.8660Epoch 00001: loss did not improve\n",
      "22500/22500 [==============================] - 5s - loss: 0.3157 - acc: 0.8664     \n",
      "Epoch 3/4\n",
      "22350/22500 [============================>.] - ETA: 0s - loss: 0.2859 - acc: 0.8795Epoch 00002: loss did not improve\n",
      "22500/22500 [==============================] - 5s - loss: 0.2860 - acc: 0.8794     \n",
      "Epoch 4/4\n",
      "22350/22500 [============================>.] - ETA: 0s - loss: 0.2609 - acc: 0.8936Epoch 00003: loss did not improve\n",
      "22500/22500 [==============================] - 5s - loss: 0.2610 - acc: 0.8933     \n",
      "2175/2500 [=========================>....] - ETA: 0sEpoch 1/4\n",
      "22350/22500 [============================>.] - ETA: 0s - loss: 0.4112 - acc: 0.8111Epoch 00000: loss did not improve\n",
      "22500/22500 [==============================] - 9s - loss: 0.4107 - acc: 0.8117     \n",
      "Epoch 2/4\n",
      "22350/22500 [============================>.] - ETA: 0s - loss: 0.3147 - acc: 0.8678Epoch 00001: loss did not improve\n",
      "22500/22500 [==============================] - 5s - loss: 0.3152 - acc: 0.8677     \n",
      "Epoch 3/4\n",
      "22350/22500 [============================>.] - ETA: 0s - loss: 0.2890 - acc: 0.8815Epoch 00002: loss did not improve\n",
      "22500/22500 [==============================] - 5s - loss: 0.2889 - acc: 0.8815     \n",
      "Epoch 4/4\n",
      "22350/22500 [============================>.] - ETA: 0s - loss: 0.2640 - acc: 0.8924Epoch 00003: loss did not improve\n",
      "22500/22500 [==============================] - 5s - loss: 0.2639 - acc: 0.8924     \n",
      "2175/2500 [=========================>....] - ETA: 0sEpoch 1/4\n",
      "22350/22500 [============================>.] - ETA: 0s - loss: 0.4105 - acc: 0.8123Epoch 00000: loss did not improve\n",
      "22500/22500 [==============================] - 9s - loss: 0.4099 - acc: 0.8126     \n",
      "Epoch 2/4\n",
      "22350/22500 [============================>.] - ETA: 0s - loss: 0.3151 - acc: 0.8677Epoch 00001: loss did not improve\n",
      "22500/22500 [==============================] - 5s - loss: 0.3148 - acc: 0.8679     \n",
      "Epoch 3/4\n",
      "22350/22500 [============================>.] - ETA: 0s - loss: 0.2901 - acc: 0.8806Epoch 00002: loss did not improve\n",
      "22500/22500 [==============================] - 5s - loss: 0.2900 - acc: 0.8807     \n",
      "Epoch 4/4\n",
      "22350/22500 [============================>.] - ETA: 0s - loss: 0.2652 - acc: 0.8909Epoch 00003: loss did not improve\n",
      "22500/22500 [==============================] - 5s - loss: 0.2657 - acc: 0.8907     \n",
      "2250/2500 [==========================>...] - ETA: 0sEpoch 1/4\n",
      "22350/22500 [============================>.] - ETA: 0s - loss: 0.4095 - acc: 0.8141Epoch 00000: loss did not improve\n",
      "22500/22500 [==============================] - 9s - loss: 0.4102 - acc: 0.8141     \n",
      "Epoch 2/4\n",
      "22350/22500 [============================>.] - ETA: 0s - loss: 0.3217 - acc: 0.8645Epoch 00001: loss did not improve\n",
      "22500/22500 [==============================] - 6s - loss: 0.3222 - acc: 0.8643     \n",
      "Epoch 3/4\n",
      "22350/22500 [============================>.] - ETA: 0s - loss: 0.2906 - acc: 0.8803Epoch 00002: loss did not improve\n",
      "22500/22500 [==============================] - 6s - loss: 0.2905 - acc: 0.8804     \n",
      "Epoch 4/4\n",
      "22350/22500 [============================>.] - ETA: 0s - loss: 0.2670 - acc: 0.8901Epoch 00003: loss did not improve\n",
      "22500/22500 [==============================] - 6s - loss: 0.2672 - acc: 0.8900     \n",
      "2175/2500 [=========================>....] - ETA: 0sEpoch 1/4\n",
      "22350/22500 [============================>.] - ETA: 0s - loss: 0.4133 - acc: 0.8055Epoch 00000: loss did not improve\n",
      "22500/22500 [==============================] - 9s - loss: 0.4124 - acc: 0.8062     \n",
      "Epoch 2/4\n",
      "22350/22500 [============================>.] - ETA: 0s - loss: 0.3141 - acc: 0.8684Epoch 00001: loss did not improve\n",
      "22500/22500 [==============================] - 6s - loss: 0.3141 - acc: 0.8684     \n",
      "Epoch 3/4\n",
      "22350/22500 [============================>.] - ETA: 0s - loss: 0.2883 - acc: 0.8782Epoch 00002: loss did not improve\n",
      "22500/22500 [==============================] - 6s - loss: 0.2880 - acc: 0.8784     \n",
      "Epoch 4/4\n",
      "22350/22500 [============================>.] - ETA: 0s - loss: 0.2625 - acc: 0.8916Epoch 00003: loss did not improve\n",
      "22500/22500 [==============================] - 6s - loss: 0.2624 - acc: 0.8917     \n",
      "2175/2500 [=========================>....] - ETA: 0sEpoch 1/4\n",
      "22350/22500 [============================>.] - ETA: 0s - loss: 0.4108 - acc: 0.8102Epoch 00000: loss did not improve\n",
      "22500/22500 [==============================] - 9s - loss: 0.4109 - acc: 0.8101     \n",
      "Epoch 2/4\n",
      "22350/22500 [============================>.] - ETA: 0s - loss: 0.3176 - acc: 0.8660Epoch 00001: loss did not improve\n",
      "22500/22500 [==============================] - 5s - loss: 0.3174 - acc: 0.8660     \n",
      "Epoch 3/4\n",
      "22350/22500 [============================>.] - ETA: 0s - loss: 0.2862 - acc: 0.8803Epoch 00002: loss did not improve\n",
      "22500/22500 [==============================] - 5s - loss: 0.2856 - acc: 0.8806     \n",
      "Epoch 4/4\n",
      "22350/22500 [============================>.] - ETA: 0s - loss: 0.2617 - acc: 0.8920Epoch 00003: loss did not improve\n",
      "22500/22500 [==============================] - 5s - loss: 0.2621 - acc: 0.8916     \n",
      "2175/2500 [=========================>....] - ETA: 0sEpoch 1/4\n",
      "22350/22500 [============================>.] - ETA: 0s - loss: 0.4068 - acc: 0.8166Epoch 00000: loss did not improve\n",
      "22500/22500 [==============================] - 9s - loss: 0.4064 - acc: 0.8169     \n",
      "Epoch 2/4\n",
      "22350/22500 [============================>.] - ETA: 0s - loss: 0.3135 - acc: 0.8686Epoch 00001: loss did not improve\n",
      "22500/22500 [==============================] - 5s - loss: 0.3134 - acc: 0.8687     \n",
      "Epoch 3/4\n",
      "22350/22500 [============================>.] - ETA: 0s - loss: 0.2878 - acc: 0.8805Epoch 00002: loss did not improve\n",
      "22500/22500 [==============================] - 5s - loss: 0.2873 - acc: 0.8808     \n",
      "Epoch 4/4\n",
      "22350/22500 [============================>.] - ETA: 0s - loss: 0.2623 - acc: 0.8912Epoch 00003: loss did not improve\n",
      "22500/22500 [==============================] - 5s - loss: 0.2626 - acc: 0.8911     \n",
      "2175/2500 [=========================>....] - ETA: 0sEpoch 1/4\n",
      "22350/22500 [============================>.] - ETA: 0s - loss: 0.4119 - acc: 0.8112Epoch 00000: loss did not improve\n",
      "22500/22500 [==============================] - 9s - loss: 0.4117 - acc: 0.8114     \n",
      "Epoch 2/4\n",
      "22350/22500 [============================>.] - ETA: 0s - loss: 0.3188 - acc: 0.8654Epoch 00001: loss did not improve\n",
      "22500/22500 [==============================] - 5s - loss: 0.3192 - acc: 0.8651     \n",
      "Epoch 3/4\n",
      "22350/22500 [============================>.] - ETA: 0s - loss: 0.2920 - acc: 0.8780Epoch 00002: loss did not improve\n",
      "22500/22500 [==============================] - 5s - loss: 0.2916 - acc: 0.8782     \n",
      "Epoch 4/4\n",
      "22350/22500 [============================>.] - ETA: 0s - loss: 0.2638 - acc: 0.8917Epoch 00003: loss did not improve\n",
      "22500/22500 [==============================] - 5s - loss: 0.2636 - acc: 0.8918     \n",
      "2175/2500 [=========================>....] - ETA: 0sEpoch 1/4\n",
      "22350/22500 [============================>.] - ETA: 0s - loss: 0.4099 - acc: 0.8138Epoch 00000: loss did not improve\n",
      "22500/22500 [==============================] - 9s - loss: 0.4094 - acc: 0.8141     \n",
      "Epoch 2/4\n",
      "22350/22500 [============================>.] - ETA: 0s - loss: 0.3192 - acc: 0.8664Epoch 00001: loss did not improve\n",
      "22500/22500 [==============================] - 5s - loss: 0.3193 - acc: 0.8663     \n",
      "Epoch 3/4\n",
      "22350/22500 [============================>.] - ETA: 0s - loss: 0.2911 - acc: 0.8786Epoch 00002: loss did not improve\n",
      "22500/22500 [==============================] - 5s - loss: 0.2912 - acc: 0.8786     \n",
      "Epoch 4/4\n",
      "22350/22500 [============================>.] - ETA: 0s - loss: 0.2666 - acc: 0.8895Epoch 00003: loss did not improve\n",
      "22500/22500 [==============================] - 5s - loss: 0.2664 - acc: 0.8897     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2250/2500 [==========================>...] - ETA: 0sEpoch 1/4\n",
      "22350/22500 [============================>.] - ETA: 0s - loss: 0.4080 - acc: 0.8159Epoch 00000: loss did not improve\n",
      "22500/22500 [==============================] - 9s - loss: 0.4077 - acc: 0.8160     \n",
      "Epoch 2/4\n",
      "22350/22500 [============================>.] - ETA: 0s - loss: 0.3132 - acc: 0.8670Epoch 00001: loss did not improve\n",
      "22500/22500 [==============================] - 5s - loss: 0.3128 - acc: 0.8672     \n",
      "Epoch 3/4\n",
      "22350/22500 [============================>.] - ETA: 0s - loss: 0.2870 - acc: 0.8799Epoch 00002: loss did not improve\n",
      "22500/22500 [==============================] - 5s - loss: 0.2867 - acc: 0.8801     \n",
      "Epoch 4/4\n",
      "22350/22500 [============================>.] - ETA: 0s - loss: 0.2623 - acc: 0.8902Epoch 00003: loss did not improve\n",
      "22500/22500 [==============================] - 5s - loss: 0.2623 - acc: 0.8901     \n",
      "2175/2500 [=========================>....] - ETA: 0sEpoch 1/2\n",
      "22230/22500 [============================>.] - ETA: 0s - loss: 0.4146 - acc: 0.8116Epoch 00000: loss did not improve\n",
      "22500/22500 [==============================] - 8s - loss: 0.4141 - acc: 0.8118     \n",
      "Epoch 2/2\n",
      "22230/22500 [============================>.] - ETA: 0s - loss: 0.3145 - acc: 0.8675Epoch 00001: loss did not improve\n",
      "22500/22500 [==============================] - 4s - loss: 0.3146 - acc: 0.8674     \n",
      "2500/2500 [==============================] - 3s     \n",
      "Epoch 1/2\n",
      "22230/22500 [============================>.] - ETA: 0s - loss: 0.4142 - acc: 0.8115Epoch 00000: loss did not improve\n",
      "22500/22500 [==============================] - 9s - loss: 0.4127 - acc: 0.8124     \n",
      "Epoch 2/2\n",
      "22230/22500 [============================>.] - ETA: 0s - loss: 0.3168 - acc: 0.8682Epoch 00001: loss did not improve\n",
      "22500/22500 [==============================] - 5s - loss: 0.3163 - acc: 0.8684     \n",
      "1980/2500 [======================>.......] - ETA: 0sEpoch 1/2\n",
      "22230/22500 [============================>.] - ETA: 0s - loss: 0.4126 - acc: 0.8118Epoch 00000: loss did not improve\n",
      "22500/22500 [==============================] - 8s - loss: 0.4114 - acc: 0.8126     \n",
      "Epoch 2/2\n",
      "22230/22500 [============================>.] - ETA: 0s - loss: 0.3144 - acc: 0.8698Epoch 00001: loss did not improve\n",
      "22500/22500 [==============================] - 4s - loss: 0.3139 - acc: 0.8700     \n",
      "1980/2500 [======================>.......] - ETA: 0sEpoch 1/2\n",
      "22230/22500 [============================>.] - ETA: 0s - loss: 0.4143 - acc: 0.8095Epoch 00000: loss did not improve\n",
      "22500/22500 [==============================] - 9s - loss: 0.4132 - acc: 0.8102     \n",
      "Epoch 2/2\n",
      "22230/22500 [============================>.] - ETA: 0s - loss: 0.3175 - acc: 0.8664Epoch 00001: loss did not improve\n",
      "22500/22500 [==============================] - 5s - loss: 0.3174 - acc: 0.8665     \n",
      "1980/2500 [======================>.......] - ETA: 0sEpoch 1/2\n",
      "22230/22500 [============================>.] - ETA: 0s - loss: 0.4141 - acc: 0.8084Epoch 00000: loss did not improve\n",
      "22500/22500 [==============================] - 8s - loss: 0.4133 - acc: 0.8090     \n",
      "Epoch 2/2\n",
      "22230/22500 [============================>.] - ETA: 0s - loss: 0.3135 - acc: 0.8696Epoch 00001: loss did not improve\n",
      "22500/22500 [==============================] - 4s - loss: 0.3141 - acc: 0.8695     \n",
      "1980/2500 [======================>.......] - ETA: 0sEpoch 1/2\n",
      "22230/22500 [============================>.] - ETA: 0s - loss: 0.4170 - acc: 0.8081Epoch 00000: loss did not improve\n",
      "22500/22500 [==============================] - 8s - loss: 0.4164 - acc: 0.8084     \n",
      "Epoch 2/2\n",
      "22230/22500 [============================>.] - ETA: 0s - loss: 0.3160 - acc: 0.8656Epoch 00001: loss did not improve\n",
      "22500/22500 [==============================] - 5s - loss: 0.3154 - acc: 0.8658     \n",
      "1980/2500 [======================>.......] - ETA: 0sEpoch 1/2\n",
      "22230/22500 [============================>.] - ETA: 0s - loss: 0.4106 - acc: 0.8131Epoch 00000: loss did not improve\n",
      "22500/22500 [==============================] - 9s - loss: 0.4095 - acc: 0.8136     \n",
      "Epoch 2/2\n",
      "22230/22500 [============================>.] - ETA: 0s - loss: 0.3134 - acc: 0.8687Epoch 00001: loss did not improve\n",
      "22500/22500 [==============================] - 5s - loss: 0.3133 - acc: 0.8687     \n",
      "1980/2500 [======================>.......] - ETA: 0sEpoch 1/2\n",
      "22230/22500 [============================>.] - ETA: 0s - loss: 0.4160 - acc: 0.8050Epoch 00000: loss did not improve\n",
      "22500/22500 [==============================] - 8s - loss: 0.4146 - acc: 0.8056     \n",
      "Epoch 2/2\n",
      "22230/22500 [============================>.] - ETA: 0s - loss: 0.3177 - acc: 0.8662Epoch 00001: loss did not improve\n",
      "22500/22500 [==============================] - 5s - loss: 0.3171 - acc: 0.8664     \n",
      "1980/2500 [======================>.......] - ETA: 0sEpoch 1/2\n",
      "22230/22500 [============================>.] - ETA: 0s - loss: 0.4186 - acc: 0.8068Epoch 00000: loss did not improve\n",
      "22500/22500 [==============================] - 9s - loss: 0.4182 - acc: 0.8071     \n",
      "Epoch 2/2\n",
      "22230/22500 [============================>.] - ETA: 0s - loss: 0.3172 - acc: 0.8647Epoch 00001: loss did not improve\n",
      "22500/22500 [==============================] - 5s - loss: 0.3178 - acc: 0.8644     \n",
      "1980/2500 [======================>.......] - ETA: 0sEpoch 1/2\n",
      "22230/22500 [============================>.] - ETA: 0s - loss: 0.4154 - acc: 0.8107Epoch 00000: loss did not improve\n",
      "22500/22500 [==============================] - 9s - loss: 0.4145 - acc: 0.8112     \n",
      "Epoch 2/2\n",
      "22230/22500 [============================>.] - ETA: 0s - loss: 0.3137 - acc: 0.8681Epoch 00001: loss did not improve\n",
      "22500/22500 [==============================] - 5s - loss: 0.3140 - acc: 0.8676     \n",
      "2500/2500 [==============================] - 3s     \n",
      "Epoch 1/3\n",
      "22230/22500 [============================>.] - ETA: 0s - loss: 0.4132 - acc: 0.8129Epoch 00000: loss did not improve\n",
      "22500/22500 [==============================] - 8s - loss: 0.4127 - acc: 0.8130     \n",
      "Epoch 2/3\n",
      "22230/22500 [============================>.] - ETA: 0s - loss: 0.3146 - acc: 0.8679Epoch 00001: loss did not improve\n",
      "22500/22500 [==============================] - 4s - loss: 0.3144 - acc: 0.8676     \n",
      "Epoch 3/3\n",
      "22230/22500 [============================>.] - ETA: 0s - loss: 0.2880 - acc: 0.8796Epoch 00002: loss did not improve\n",
      "22500/22500 [==============================] - 4s - loss: 0.2882 - acc: 0.8795     \n",
      "1980/2500 [======================>.......] - ETA: 0sEpoch 1/3\n",
      "22230/22500 [============================>.] - ETA: 0s - loss: 0.4155 - acc: 0.8094Epoch 00000: loss did not improve\n",
      "22500/22500 [==============================] - 8s - loss: 0.4147 - acc: 0.8101     \n",
      "Epoch 2/3\n",
      "22230/22500 [============================>.] - ETA: 0s - loss: 0.3159 - acc: 0.8674Epoch 00001: loss did not improve\n",
      "22500/22500 [==============================] - 4s - loss: 0.3159 - acc: 0.8672     \n",
      "Epoch 3/3\n",
      "22230/22500 [============================>.] - ETA: 0s - loss: 0.2885 - acc: 0.8802Epoch 00002: loss did not improve\n",
      "22500/22500 [==============================] - 4s - loss: 0.2889 - acc: 0.8802     \n",
      "2500/2500 [==============================] - 3s     \n",
      "Epoch 1/3\n",
      "22230/22500 [============================>.] - ETA: 0s - loss: 0.4163 - acc: 0.8087Epoch 00000: loss did not improve\n",
      "22500/22500 [==============================] - 9s - loss: 0.4161 - acc: 0.8088     \n",
      "Epoch 2/3\n",
      "22230/22500 [============================>.] - ETA: 0s - loss: 0.3180 - acc: 0.8659Epoch 00001: loss did not improve\n",
      "22500/22500 [==============================] - 5s - loss: 0.3177 - acc: 0.8660     \n",
      "Epoch 3/3\n",
      "22230/22500 [============================>.] - ETA: 0s - loss: 0.2872 - acc: 0.8806Epoch 00002: loss did not improve\n",
      "22500/22500 [==============================] - 5s - loss: 0.2871 - acc: 0.8808     \n",
      "2430/2500 [============================>.] - ETA: 0sEpoch 1/3\n",
      "22230/22500 [============================>.] - ETA: 0s - loss: 0.4120 - acc: 0.8125Epoch 00000: loss did not improve\n",
      "22500/22500 [==============================] - 9s - loss: 0.4119 - acc: 0.8126     \n",
      "Epoch 2/3\n",
      "22230/22500 [============================>.] - ETA: 0s - loss: 0.3180 - acc: 0.8667Epoch 00001: loss did not improve\n",
      "22500/22500 [==============================] - 5s - loss: 0.3181 - acc: 0.8665     \n",
      "Epoch 3/3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22230/22500 [============================>.] - ETA: 0s - loss: 0.2913 - acc: 0.8793Epoch 00002: loss did not improve\n",
      "22500/22500 [==============================] - 5s - loss: 0.2917 - acc: 0.8789     \n",
      "2500/2500 [==============================] - 3s     \n",
      "Epoch 1/3\n",
      "22230/22500 [============================>.] - ETA: 0s - loss: 0.4130 - acc: 0.8121Epoch 00000: loss did not improve\n",
      "22500/22500 [==============================] - 9s - loss: 0.4119 - acc: 0.8129     \n",
      "Epoch 2/3\n",
      "22230/22500 [============================>.] - ETA: 0s - loss: 0.3133 - acc: 0.8682Epoch 00001: loss did not improve\n",
      "22500/22500 [==============================] - 5s - loss: 0.3130 - acc: 0.8681     \n",
      "Epoch 3/3\n",
      "22230/22500 [============================>.] - ETA: 0s - loss: 0.2858 - acc: 0.8801Epoch 00002: loss did not improve\n",
      "22500/22500 [==============================] - 5s - loss: 0.2857 - acc: 0.8802     \n",
      "2430/2500 [============================>.] - ETA: 0sEpoch 1/3\n",
      "22230/22500 [============================>.] - ETA: 0s - loss: 0.4125 - acc: 0.8121Epoch 00000: loss did not improve\n",
      "22500/22500 [==============================] - 9s - loss: 0.4115 - acc: 0.8126     \n",
      "Epoch 2/3\n",
      "22230/22500 [============================>.] - ETA: 0s - loss: 0.3161 - acc: 0.8695Epoch 00001: loss did not improve\n",
      "22500/22500 [==============================] - 5s - loss: 0.3163 - acc: 0.8694     \n",
      "Epoch 3/3\n",
      "22230/22500 [============================>.] - ETA: 0s - loss: 0.2897 - acc: 0.8799Epoch 00002: loss did not improve\n",
      "22500/22500 [==============================] - 5s - loss: 0.2892 - acc: 0.8801     \n",
      "2500/2500 [==============================] - 3s     \n",
      "Epoch 1/3\n",
      "22230/22500 [============================>.] - ETA: 0s - loss: 0.4145 - acc: 0.8085Epoch 00000: loss did not improve\n",
      "22500/22500 [==============================] - 9s - loss: 0.4141 - acc: 0.8088     \n",
      "Epoch 2/3\n",
      "22230/22500 [============================>.] - ETA: 0s - loss: 0.3159 - acc: 0.8648Epoch 00001: loss did not improve\n",
      "22500/22500 [==============================] - 5s - loss: 0.3158 - acc: 0.8649     \n",
      "Epoch 3/3\n",
      "22230/22500 [============================>.] - ETA: 0s - loss: 0.2898 - acc: 0.8783Epoch 00002: loss did not improve\n",
      "22500/22500 [==============================] - 5s - loss: 0.2892 - acc: 0.8786     \n",
      "2500/2500 [==============================] - 3s     \n",
      "Epoch 1/3\n",
      "22230/22500 [============================>.] - ETA: 0s - loss: 0.4167 - acc: 0.8088Epoch 00000: loss did not improve\n",
      "22500/22500 [==============================] - 9s - loss: 0.4157 - acc: 0.8094     \n",
      "Epoch 2/3\n",
      "22230/22500 [============================>.] - ETA: 0s - loss: 0.3196 - acc: 0.8631Epoch 00001: loss did not improve\n",
      "22500/22500 [==============================] - 5s - loss: 0.3199 - acc: 0.8629     \n",
      "Epoch 3/3\n",
      "22230/22500 [============================>.] - ETA: 0s - loss: 0.2914 - acc: 0.8792Epoch 00002: loss did not improve\n",
      "22500/22500 [==============================] - 5s - loss: 0.2909 - acc: 0.8792     \n",
      "2430/2500 [============================>.] - ETA: 0sEpoch 1/3\n",
      "22230/22500 [============================>.] - ETA: 0s - loss: 0.4176 - acc: 0.8111Epoch 00000: loss did not improve\n",
      "22500/22500 [==============================] - 9s - loss: 0.4171 - acc: 0.8112     \n",
      "Epoch 2/3\n",
      "22230/22500 [============================>.] - ETA: 0s - loss: 0.3166 - acc: 0.8664Epoch 00001: loss did not improve\n",
      "22500/22500 [==============================] - 5s - loss: 0.3173 - acc: 0.8660     \n",
      "Epoch 3/3\n",
      "22230/22500 [============================>.] - ETA: 0s - loss: 0.2902 - acc: 0.8780Epoch 00002: loss did not improve\n",
      "22500/22500 [==============================] - 5s - loss: 0.2901 - acc: 0.8779     \n",
      "1980/2500 [======================>.......] - ETA: 0sEpoch 1/3\n",
      "22230/22500 [============================>.] - ETA: 0s - loss: 0.4143 - acc: 0.8118Epoch 00000: loss did not improve\n",
      "22500/22500 [==============================] - 9s - loss: 0.4135 - acc: 0.8122     \n",
      "Epoch 2/3\n",
      "22230/22500 [============================>.] - ETA: 0s - loss: 0.3182 - acc: 0.8664Epoch 00001: loss did not improve\n",
      "22500/22500 [==============================] - 5s - loss: 0.3178 - acc: 0.8667     \n",
      "Epoch 3/3\n",
      "22230/22500 [============================>.] - ETA: 0s - loss: 0.2896 - acc: 0.8794Epoch 00002: loss did not improve\n",
      "22500/22500 [==============================] - 5s - loss: 0.2895 - acc: 0.8795     \n",
      "1980/2500 [======================>.......] - ETA: 0sEpoch 1/4\n",
      "22230/22500 [============================>.] - ETA: 0s - loss: 0.4116 - acc: 0.8105Epoch 00000: loss did not improve\n",
      "22500/22500 [==============================] - 9s - loss: 0.4105 - acc: 0.8114     \n",
      "Epoch 2/4\n",
      "22230/22500 [============================>.] - ETA: 0s - loss: 0.3169 - acc: 0.8664Epoch 00001: loss did not improve\n",
      "22500/22500 [==============================] - 5s - loss: 0.3163 - acc: 0.8666     \n",
      "Epoch 3/4\n",
      "22230/22500 [============================>.] - ETA: 0s - loss: 0.2882 - acc: 0.8809Epoch 00002: loss did not improve\n",
      "22500/22500 [==============================] - 5s - loss: 0.2878 - acc: 0.8812     \n",
      "Epoch 4/4\n",
      "22230/22500 [============================>.] - ETA: 0s - loss: 0.2628 - acc: 0.8924Epoch 00003: loss did not improve\n",
      "22500/22500 [==============================] - 5s - loss: 0.2626 - acc: 0.8925     \n",
      "2500/2500 [==============================] - 3s     \n",
      "Epoch 1/4\n",
      "22230/22500 [============================>.] - ETA: 0s - loss: 0.4115 - acc: 0.8132Epoch 00000: loss did not improve\n",
      "22500/22500 [==============================] - 9s - loss: 0.4105 - acc: 0.8139     \n",
      "Epoch 2/4\n",
      "22230/22500 [============================>.] - ETA: 0s - loss: 0.3139 - acc: 0.8687Epoch 00001: loss did not improve\n",
      "22500/22500 [==============================] - 5s - loss: 0.3141 - acc: 0.8686     \n",
      "Epoch 3/4\n",
      "22230/22500 [============================>.] - ETA: 0s - loss: 0.2881 - acc: 0.8786Epoch 00002: loss did not improve\n",
      "22500/22500 [==============================] - 5s - loss: 0.2886 - acc: 0.8784     \n",
      "Epoch 4/4\n",
      "22230/22500 [============================>.] - ETA: 0s - loss: 0.2643 - acc: 0.8918Epoch 00003: loss did not improve\n",
      "22500/22500 [==============================] - 5s - loss: 0.2638 - acc: 0.8920     \n",
      "2500/2500 [==============================] - 3s     \n",
      "Epoch 1/4\n",
      "22230/22500 [============================>.] - ETA: 0s - loss: 0.4091 - acc: 0.8141Epoch 00000: loss did not improve\n",
      "22500/22500 [==============================] - 9s - loss: 0.4092 - acc: 0.8142     \n",
      "Epoch 2/4\n",
      "22230/22500 [============================>.] - ETA: 0s - loss: 0.3148 - acc: 0.8690Epoch 00001: loss did not improve\n",
      "22500/22500 [==============================] - 5s - loss: 0.3151 - acc: 0.8687     \n",
      "Epoch 3/4\n",
      "22230/22500 [============================>.] - ETA: 0s - loss: 0.2891 - acc: 0.8784Epoch 00002: loss did not improve\n",
      "22500/22500 [==============================] - 5s - loss: 0.2891 - acc: 0.8784     \n",
      "Epoch 4/4\n",
      "22230/22500 [============================>.] - ETA: 0s - loss: 0.2639 - acc: 0.8934Epoch 00003: loss did not improve\n",
      "22500/22500 [==============================] - 5s - loss: 0.2645 - acc: 0.8932     \n",
      "2500/2500 [==============================] - 3s     \n",
      "Epoch 1/4\n",
      "22230/22500 [============================>.] - ETA: 0s - loss: 0.4171 - acc: 0.8077Epoch 00000: loss did not improve\n",
      "22500/22500 [==============================] - 9s - loss: 0.4165 - acc: 0.8080     \n",
      "Epoch 2/4\n",
      "22230/22500 [============================>.] - ETA: 0s - loss: 0.3195 - acc: 0.8649Epoch 00001: loss did not improve\n",
      "22500/22500 [==============================] - 5s - loss: 0.3192 - acc: 0.8652     \n",
      "Epoch 3/4\n",
      "22230/22500 [============================>.] - ETA: 0s - loss: 0.2884 - acc: 0.8815Epoch 00002: loss did not improve\n",
      "22500/22500 [==============================] - 5s - loss: 0.2890 - acc: 0.8813     \n",
      "Epoch 4/4\n",
      "22230/22500 [============================>.] - ETA: 0s - loss: 0.2632 - acc: 0.8911Epoch 00003: loss did not improve\n",
      "22500/22500 [==============================] - 5s - loss: 0.2628 - acc: 0.8912     \n",
      "2340/2500 [===========================>..] - ETA: 0sEpoch 1/4\n",
      "22230/22500 [============================>.] - ETA: 0s - loss: 0.4131 - acc: 0.8082Epoch 00000: loss did not improve\n",
      "22500/22500 [==============================] - 9s - loss: 0.4121 - acc: 0.8086     \n",
      "Epoch 2/4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22230/22500 [============================>.] - ETA: 0s - loss: 0.3161 - acc: 0.8667Epoch 00001: loss did not improve\n",
      "22500/22500 [==============================] - 5s - loss: 0.3151 - acc: 0.8670     \n",
      "Epoch 3/4\n",
      "22230/22500 [============================>.] - ETA: 0s - loss: 0.2852 - acc: 0.8803Epoch 00002: loss did not improve\n",
      "22500/22500 [==============================] - 5s - loss: 0.2855 - acc: 0.8802     \n",
      "Epoch 4/4\n",
      "22230/22500 [============================>.] - ETA: 0s - loss: 0.2605 - acc: 0.8925Epoch 00003: loss did not improve\n",
      "22500/22500 [==============================] - 5s - loss: 0.2598 - acc: 0.8930     \n",
      "2500/2500 [==============================] - 3s     \n",
      "Epoch 1/4\n",
      "22230/22500 [============================>.] - ETA: 0s - loss: 0.4156 - acc: 0.8094Epoch 00000: loss did not improve\n",
      "22500/22500 [==============================] - 9s - loss: 0.4148 - acc: 0.8100     \n",
      "Epoch 2/4\n",
      "22230/22500 [============================>.] - ETA: 0s - loss: 0.3167 - acc: 0.8675Epoch 00001: loss did not improve\n",
      "22500/22500 [==============================] - 5s - loss: 0.3165 - acc: 0.8676     \n",
      "Epoch 3/4\n",
      "22230/22500 [============================>.] - ETA: 0s - loss: 0.2909 - acc: 0.8787Epoch 00002: loss did not improve\n",
      "22500/22500 [==============================] - 5s - loss: 0.2910 - acc: 0.8787     \n",
      "Epoch 4/4\n",
      "22230/22500 [============================>.] - ETA: 0s - loss: 0.2641 - acc: 0.8937Epoch 00003: loss did not improve\n",
      "22500/22500 [==============================] - 5s - loss: 0.2642 - acc: 0.8935     \n",
      "2500/2500 [==============================] - 3s     \n",
      "Epoch 1/4\n",
      "22230/22500 [============================>.] - ETA: 0s - loss: 0.4139 - acc: 0.8106Epoch 00000: loss did not improve\n",
      "22500/22500 [==============================] - 9s - loss: 0.4130 - acc: 0.8112     \n",
      "Epoch 2/4\n",
      "22230/22500 [============================>.] - ETA: 0s - loss: 0.3169 - acc: 0.8646Epoch 00001: loss did not improve\n",
      "22500/22500 [==============================] - 5s - loss: 0.3167 - acc: 0.8646     \n",
      "Epoch 3/4\n",
      "22230/22500 [============================>.] - ETA: 0s - loss: 0.2848 - acc: 0.8812Epoch 00002: loss did not improve\n",
      "22500/22500 [==============================] - 5s - loss: 0.2854 - acc: 0.8812     \n",
      "Epoch 4/4\n",
      "22230/22500 [============================>.] - ETA: 0s - loss: 0.2613 - acc: 0.8925Epoch 00003: loss did not improve\n",
      "22500/22500 [==============================] - 5s - loss: 0.2615 - acc: 0.8926     \n",
      "2430/2500 [============================>.] - ETA: 0sEpoch 1/4\n",
      "22230/22500 [============================>.] - ETA: 0s - loss: 0.4149 - acc: 0.8108Epoch 00000: loss did not improve\n",
      "22500/22500 [==============================] - 9s - loss: 0.4145 - acc: 0.8109     \n",
      "Epoch 2/4\n",
      "22230/22500 [============================>.] - ETA: 0s - loss: 0.3174 - acc: 0.8651Epoch 00001: loss did not improve\n",
      "22500/22500 [==============================] - 5s - loss: 0.3172 - acc: 0.8655     \n",
      "Epoch 3/4\n",
      "22230/22500 [============================>.] - ETA: 0s - loss: 0.2886 - acc: 0.8792Epoch 00002: loss did not improve\n",
      "22500/22500 [==============================] - 5s - loss: 0.2881 - acc: 0.8795     \n",
      "Epoch 4/4\n",
      "22230/22500 [============================>.] - ETA: 0s - loss: 0.2658 - acc: 0.8904Epoch 00003: loss did not improve\n",
      "22500/22500 [==============================] - 5s - loss: 0.2657 - acc: 0.8905     \n",
      "2430/2500 [============================>.] - ETA: 0sEpoch 1/4\n",
      "22230/22500 [============================>.] - ETA: 0s - loss: 0.4125 - acc: 0.8145Epoch 00000: loss did not improve\n",
      "22500/22500 [==============================] - 9s - loss: 0.4122 - acc: 0.8146     \n",
      "Epoch 2/4\n",
      "22230/22500 [============================>.] - ETA: 0s - loss: 0.3184 - acc: 0.8668Epoch 00001: loss did not improve\n",
      "22500/22500 [==============================] - 5s - loss: 0.3186 - acc: 0.8667     \n",
      "Epoch 3/4\n",
      "22230/22500 [============================>.] - ETA: 0s - loss: 0.2905 - acc: 0.8803Epoch 00002: loss did not improve\n",
      "22500/22500 [==============================] - 5s - loss: 0.2902 - acc: 0.8805     \n",
      "Epoch 4/4\n",
      "22230/22500 [============================>.] - ETA: 0s - loss: 0.2686 - acc: 0.8913Epoch 00003: loss did not improve\n",
      "22500/22500 [==============================] - 5s - loss: 0.2689 - acc: 0.8911     \n",
      "2430/2500 [============================>.] - ETA: 0sEpoch 1/4\n",
      "22230/22500 [============================>.] - ETA: 0s - loss: 0.4098 - acc: 0.8140Epoch 00000: loss did not improve\n",
      "22500/22500 [==============================] - 9s - loss: 0.4085 - acc: 0.8147     \n",
      "Epoch 2/4\n",
      "22230/22500 [============================>.] - ETA: 0s - loss: 0.3161 - acc: 0.8659Epoch 00001: loss did not improve\n",
      "22500/22500 [==============================] - 5s - loss: 0.3160 - acc: 0.8661     \n",
      "Epoch 3/4\n",
      "22230/22500 [============================>.] - ETA: 0s - loss: 0.2890 - acc: 0.8778Epoch 00002: loss did not improve\n",
      "22500/22500 [==============================] - 5s - loss: 0.2888 - acc: 0.8778     \n",
      "Epoch 4/4\n",
      "22230/22500 [============================>.] - ETA: 0s - loss: 0.2666 - acc: 0.8917Epoch 00003: loss did not improve\n",
      "22500/22500 [==============================] - 5s - loss: 0.2668 - acc: 0.8915     \n",
      "1980/2500 [======================>.......] - ETA: 0sEpoch 1/3\n",
      "24825/25000 [============================>.] - ETA: 0s - loss: 0.4015 - acc: 0.8190Epoch 00000: loss did not improve\n",
      "25000/25000 [==============================] - 10s - loss: 0.4019 - acc: 0.8190    \n",
      "Epoch 2/3\n",
      "24825/25000 [============================>.] - ETA: 0s - loss: 0.3156 - acc: 0.8650Epoch 00001: loss did not improve\n",
      "25000/25000 [==============================] - 6s - loss: 0.3155 - acc: 0.8650     \n",
      "Epoch 3/3\n",
      "24825/25000 [============================>.] - ETA: 0s - loss: 0.2910 - acc: 0.8796Epoch 00002: loss did not improve\n",
      "25000/25000 [==============================] - 6s - loss: 0.2907 - acc: 0.8799     \n"
     ]
    }
   ],
   "source": [
    "checkpointer = ModelCheckpoint('./weights_3.hdf5', monitor='loss', verbose=1,\n",
    "                               save_best_only=True, mode='min')\n",
    "\n",
    "classifier = KerasClassifier(build_fn = construct_model)\n",
    "\n",
    "parameters = {'batch_size': [60, 75, 90],\n",
    "              'epochs': [2, 3, 4],\n",
    "              'optimizer':[adam]}\n",
    "\n",
    "grid_search = GridSearchCV(estimator = classifier,\n",
    "                           param_grid = parameters,\n",
    "                           fit_params={'callbacks': [checkpointer]},\n",
    "                           scoring = 'log_loss',\n",
    "                           cv = 10)\n",
    "\n",
    "grid_search = grid_search.fit(x_train_tok, y_train_tok)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_parameters = grid_search.best_params_\n",
    "best_score = grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_size': 75,\n",
       " 'epochs': 3,\n",
       " 'optimizer': <keras.optimizers.Adam at 0x7f59f57816d8>}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.3254009095551621"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24675/25000 [============================>.] - ETA: 0s"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       ..., \n",
       "       [ 1.],\n",
       "       [ 0.],\n",
       "       [ 1.]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_estimator_.predict(x_test_tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.86064\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(model_builder=construct_model, optimizer=adam, weights='weights_3.hdf5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
